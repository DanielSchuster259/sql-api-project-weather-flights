{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Build connection, send data to database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://gcn.com/articles/2017/12/05/-/media/GIG/GCN/Redesign/Articles/2017/December/flightdata.png\", width = 800)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**In this notebook, we will**\n",
    "1. Set up a connection to a SQL database \n",
    "2. Download a csv file\n",
    "3. Prepare the data for further processing\n",
    "4. Push the prepared data to a table in the database\n",
    "5. Use SQL to query data from the database\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from zipfile import *\n",
    "from sqlalchemy import exc #SQLAlchemy provides a nice “Pythonic” way of interacting with databases.\n",
    "from sqlalchemy import event"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will go through this workflow step by step before we include all single steps into one, big, main function which does all the steps at once.  \n",
    "For our puropse, we will use public **flight data**. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Set up a connection to a SQL database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start with connecting to an existing sql database, so that we can check what is already there and to send data to a table in the database later on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Establish db connection\n",
    "from sql import conn\n",
    "# Use code from data sourcing notebooks\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Download csv file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following, you are going to download a csv file containing additional flight data from [this website](https://transtats.bts.gov).    \n",
    "You can specify, which data you want to download.  \n",
    "We want you to choose a specific month in a specific year for your download.  \n",
    "In order to avoid everybody's downloading the same data, first check which months are already available in the flights table:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#First, check which months are not in the database yet.\n",
    "months = engine.execute('select distinct(year, month) from flights').fetchall()\n",
    "months"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, choose a month/year that is not yet in the database.  \n",
    "With the following command lines, you will download a csv file on public flight data from [this website](https://transtats.bts.gov) containing data of your chosen month/year.    \n",
    "The file will be stored in a data folder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "years = [2018] # list of years you want to look at, specify one year\n",
    "months = [9] # list of months you want to look at, specify one month\n",
    "# Here: September 2018 which is in the list already\n",
    "path ='data/' # Specifies path for saving file\n",
    "\n",
    "# Loop through months\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        # Get the file from the website https://transtats.bts.gov\n",
    "        zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "        csv_file = f'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv'\n",
    "        url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "        arg = f' -P {path} --no-check-certificate'\n",
    "        # Use the wget Module to download the file. The method accepts two parameters: the URL path of the file to download and local path where the file is to be stored.\n",
    "        !wget {url}{arg} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Unzip your file\n",
    "with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n",
    "    \n",
    "# In casee this does not work for you try:\n",
    "# Instead of 'from zipfile import *' use 'import zipfile' and use 'with zipfile.ZipFile(path+zip_file, 'r')'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read in your data\n",
    "df = pd.read_csv(path+csv_file, low_memory = False)\n",
    "display(df.shape)\n",
    "display(df.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Prepare the csv file for further processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next step, we clean and prepare our dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Since the dataset consists of a lot of columns, we we define which ones to keep."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The columns in the DB have different naming as in the source csv files. Lets get the names from the DB\n",
    "table_name_sql = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'flights' ORDER BY ordinal_position\"\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Just in case the above fails\n",
    "c_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \n",
    "                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'distance', 'cancelled', 'diverted' ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we can clean up the results into a clean list\n",
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) With the next function, we make our csv file ready to be uploaded to SQL.  \n",
    "We only keep to above specified columns and convert the datatypes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Call function and check resulting dataframe\n",
    "df_clean = clean_airline_df(df)\n",
    "df_clean.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you decide to only look at specific airports, it is a good decision to filter for them in advance.  \n",
    "This function does the filtering. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify the airports you are interested in and put them as a list in the function.\n",
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering airline df for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Execute function, filtering for New York area airports\n",
    "airports=['JFK', 'LGA', 'EWR']\n",
    "if len(airports) > 0:\n",
    "    df_airline = select_airport(df_clean, airports)\n",
    "else:\n",
    "    df_airline = df_clean\n",
    "    \n",
    "df_airline.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Push the prepared data to a table in the database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify which table within your database you want to push your data to. For our case, use the nyflights table.\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'append', your data will be appended to the already existing data within the table nyflights.\n",
    "# This will take a minute or two...\n",
    "\n",
    "table = 'flights'\n",
    "\n",
    "# Sends your data to specified table, via the etablished connection\n",
    "df_airline.to_sql(table, engine, index=False, if_exists=\"append\", \n",
    "    method='multi', chunksize=5000)\n",
    "print(f'done uploading {year}-{month}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Use SQL to query data from the database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tasks\n",
    "Having sent the data to the database, it is always good to check the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Check the top 5 rows of the nyflights table (as we did above)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Check if your data has been added by selecting your month and year."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. See how many rows you have sent to the database by selecting your month and year in combination with count and group by."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Wrap-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function puts everything we did above together.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def airline_csv_to_sql(years=[2020], months=[2], path ='data/', table='nyflights', airports=['JFK', 'LGA', 'EWR']):\n",
    "    '''Downloads and unzips the flight data from BTS. Then Sends to SQL Database'''\n",
    "    \n",
    "    # Establish db connection\n",
    "    params = config(section='postgres')\n",
    "    engine = pg_engine_connection(**params)\n",
    "    engine.dispose()\n",
    "\n",
    "    # Loop through months\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            # Get the file\n",
    "            zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "            csv_file = f'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv'\n",
    "            url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "            arg = f' -P {path} --no-check-certificate'\n",
    "            !wget {url}{arg} \n",
    "\n",
    "            # unzip\n",
    "            with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "            \n",
    "            # prepare df\n",
    "            df_airline = pd.read_csv(path+csv_file, low_memory=False)\n",
    "            df_airline = clean_airline_df(df_airline)\n",
    "            \n",
    "            # Select specific airports \n",
    "            if len(airports) > 0:\n",
    "                df_airline = select_airport(df_airline, airports)\n",
    "\n",
    "            # to SQL\n",
    "            print(f'starting uploading {df_airline.shape[0]} rows from {year}-{month}')\n",
    "            df_airline.to_sql(table, engine, index=False, if_exists=\"append\", \n",
    "                  method='multi', chunksize=5000)\n",
    "            print(f'done uploading {year}-{month}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sql-practice] *",
   "language": "python",
   "name": "conda-env-sql-practice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}